---
title: "p8105_hw6_sx2402"
author: "Eric Xu"
date: "2025-11-28"
output: html_document
---
```{r setup, include=FALSE}
library(tidyverse)
library(knitr)
library(p8105.datasets)
library(broom)
library(purrr)
```

## Problem 1

---

### 1. Import and prepare data

```{r P1.1, message = FALSE}
homicide_raw = read_csv(
  "https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv"
)

homicide_df = homicide_raw |>
  janitor::clean_names() |>
  mutate(
    city_state = str_c(city, ", ", state),
    resolved = if_else(disposition == "Closed by arrest", 1, 0),
    resolved = as.numeric(resolved),
    victim_age = case_when(victim_age == "Unknown" ~ NA, .default = victim_age),
    victim_age = as.numeric(victim_age),
    victim_race = fct_relevel(victim_race, "White")
  ) |>
  filter(
    !city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL"),
    victim_race %in% c("White", "Black")
  ) |>
  mutate(
    victim_sex = fct_relevel(victim_sex, "Female"),
    victim_race = fct_relevel(victim_race, "White")
  )
```

Fit logistic regression on Baltimore data.

```{r P1.2}
baltimore_df = homicide_df |>
  filter(city_state == "Baltimore, MD")

baltimore_fit = 
  baltimore_df |> 
  glm(resolved ~ victim_age + victim_race + victim_sex, data = _, family = binomial()) 



baltimore_results = baltimore_fit |>
  tidy(conf.int = TRUE, exponentiate = TRUE) |>
  filter(term == "victim_sexMale") |>
  select(term, estimate, conf.low, conf.high)

kable(baltimore_results)
```

Fit for city in one pipeline
```{r P1.3, warning = FALSE}
city_results = homicide_df |>
  group_by(city_state) |>
  nest() |>
  mutate(
    model = map(
      data, 
      ~ glm(
          resolved ~ victim_age + victim_race + victim_sex,
          data = .x,
          family = binomial()
        )
    )
    ) |> 
  mutate(
    tidy = map(
      model,
      ~ tidy(.x, conf.int = TRUE, exponentiate = TRUE)
    )
  ) |> 
  unnest(tidy) |> 
  filter(term == "victim_sexMale") |>
    mutate(
    adjusted_OR = estimate
  ) |> 
  select(
    city_state,
    adjusted_OR,
    conf.low, 
    conf.high
  )
kable(city_results)
```

Plotting the adjusted odds ratios.
```{r P1.4, fig_height = 12, fig.width=7}
city_plot = city_results |> 
  ggplot(aes(x = adjusted_OR, y = fct_reorder(city_state, adjusted_OR)))+
  geom_point() +
  geom_errorbar(aes(xmin = conf.low, xmax = conf.high)) +
  geom_vline(xintercept = 1, linetype = "dashed", color = "red") +
  labs(
    title = "Adjusted OR: Male vs Female Victim",
    x = "Adjusted OR",
    y = NULL
  ) +
  theme_minimal()+
  theme(
    axis.text.y = element_text(size = 6)
  )
city_plot
```

Comment:
A half of the cities have a wide confidence interval including the null value. This suggests not enough evidence of male victims having higher odds of resolved cases compared to female after adjusting for race and age. Other cities showing a significance usually have a odds ratio smaller than 1. This shows that in these cities, it is statistically significant that male victims have lower odds of resolved cases compared to female after adjusting for race and age. The lower OR estimates are more stable with lower SE and narrow CI.

## Problem 2

---

```{r P2, cache = TRUE}
data("weather_df")

boot_df = weather_df |>
  drop_na(tmax, tmin, prcp) |> 
  modelr::bootstrap(n = 5000) |>
  mutate(
    models = map(strap, \(df) lm(tmax ~ tmin + prcp, data = df) ),
    results = map(models, tidy),
    glance = map(models, glance)) |> 
  select(-strap, -models) |> 
  unnest(results, names_sep = "_") |>
  unnest(glance, names_sep = "_")

boot_results = boot_df |> group_by(.id,results_term) |> 
  mutate(
    r2 = glance_r.squared
  ) |> 
  select(results_term,results_estimate,r2,.id) |> 
    pivot_wider(
    names_from = results_term,
    values_from = results_estimate
  ) |>
  mutate(
    beta_ratio = tmin / prcp
  )

boot_plot = boot_results |>
  select(r2, beta_ratio,.id) |>
  pivot_longer(
    cols = c(r2, beta_ratio),
    names_to = "estimate",
    values_to = "value"
  )
boot_plot |> 
  ggplot(aes(x = value)) +
  geom_density(fill = "steelblue", alpha = 0.5) +
  facet_wrap(vars(estimate),scales = "free") +
  theme_minimal() +
  labs(
    title = "Bootstrap Distributions",
    x = "Estimate",
    y = "Density"
  )

```

Both r squared and beta quotient in plot are slightly left skewed distribution. While it is unimodal and approximately symmetric, this suggests that the bootstrap procedure is stable and that the statistics behave regularly under repeated sampling.

```{r P2.1, cache = TRUE}
boot_ci = boot_plot |>
  group_by(estimate) |> 
  summarize(
    ci_lower = quantile(value, 0.025),
    ci_upper = quantile(value, 0.975)
  )
kable(boot_ci, digits = 3)
```


## Problem 3
```{r}
brithweight_data = read.csv("birthweight.csv")
```

